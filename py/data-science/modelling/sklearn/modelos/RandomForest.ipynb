{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O principal problema das árvores de decisão é de que elas tendem ao overfitting, ou seja, se adequar quase que perfeitamente ao conjunto de dados analisado. Isso significa que elas possuem **alta variância**, i.e., podem ser criadas árvores totalmente diferentes em cima de um outro subconjunto dos dados de treinamento (ainda que possuam o mesmo Proceso Gerador de Dados).\n",
    "\n",
    "Uma forma de reduzir isso é criar diversas árvores de decisão diferentes em cima de diversos subconjuntos dos dados de forma aleatória e com repetição (bootstrapping), selecionando inclusive as variáveis independentes de forma aleatória a fim de \"descorrelacionar\" os modelos ao máximo. A partir daí podemos analisar a resposta conjunta de diversos modelos, sendo este o cerne da criação das Random Forests. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Obs.:** A Random Forest pode ser resumida como um modelo *ensemble* de várias àrvores de decisão. Modelos *ensemble* constroem diversos modelos e analisam a sua resposta agregada como resultado da análise preditiva, e cada um possui suas peculiaridades. Em casos onde são utilizados subconjuntos aleatórios da base para treinamento, chamamos isto de bootstrapping aggregation (bagging)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prós:\n",
    "\n",
    "* Performance\n",
    "* Alta capacidade de generalização\n",
    "\n",
    "Contras: \n",
    "* Interpretabilidade\n",
    "* Gasto computacional elevado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construindo o Algoritmo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importação das Bibliotecas e Manipulação dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, roc_curve, auc, RocCurveDisplay\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../dados/titanic.csv\")\n",
    "df.drop([\"PassengerId\", \"Name\", \"SibSp\", \"Ticket\", \"Cabin\", \"Embarked\", \"Parch\"], axis = 1, inplace = True)\n",
    "df[\"Sex\"] = np.where(df[\"Sex\"] == \"male\", 1, 0)\n",
    "df.dropna(inplace = True)\n",
    "df.head() # Alvo Binário: Survived\n",
    "\n",
    "X = df.drop(\"Survived\", axis = 1)\n",
    "y = df[\"Survived\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ajuste do Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = RandomForestClassifier(random_state = 42) # gera um modelo aleatório a cada vez que rodamos o código\n",
    "modelo.fit(X_train, y_train)\n",
    "y_pred = modelo.predict(X_test)\n",
    "y_pred_train = modelo.predict(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Métricas de Avaliação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8549618320610687\n"
     ]
    }
   ],
   "source": [
    "# Acurácia\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[142  20]\n",
      " [ 18  82]]\n"
     ]
    }
   ],
   "source": [
    "# Matriz de Confusão\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.88      0.88       162\n",
      "           1       0.80      0.82      0.81       100\n",
      "\n",
      "    accuracy                           0.85       262\n",
      "   macro avg       0.85      0.85      0.85       262\n",
      "weighted avg       0.86      0.85      0.86       262\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Métricas de Avaliação\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC - Teste : 0.8482716049382715\n"
     ]
    }
   ],
   "source": [
    "# Calculando a AUC (Area Under the Curve)\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "print(\"AUC - Teste :\", roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Otimização"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O algoritmo de Random Forest é amplamente reconhecido pela sua baixa necessidade de otimização, tendo em vista que permite estimar diferentes modelos em diferentes estágios da base de treinamento. Ainda assim, algumas escolhas de hiperparâmetros podem ser consideradas. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hiperparâmetros a serem otimizados:\n",
    "* n_estimators -> número de árvores distintas estimadas (padrão: 10 -> pode ser muito pequeno)\n",
    "* max_features -> número máximo de variáveis independentes a ser considerado em cada nó das árvores de decisão (padrão: raiz quadrada da quantidade de variáveis independentes imputada ao modelo, o que é uma boa medida)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Gráfico de Cotovelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O parâmetro `n_estimators` nunca leva à queda de performance, somente aumenta o gasto computacional. Para corrigir esse problema e encontrar o melhor modelo (trade-off custo x resultado), deve-se criar o gráfico de cotovelo (Elbow Graph) e testar diferentes valores para esse hiperparâmetro.\n",
    "\n",
    "Para isso realizamos um `GridSearch` com diversos valores e podemos plotar o atributo cv_results_ obtido, que contém certa métrica de avaliação escolhida (geralmente ['mean_test_score']) para cada modelo testado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Feature Importances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para cada árvore de decisão estimada no RandomForest, o modelo realiza a divisão do conjunto de dados tendo como objetivo a máxima redução de impuridade. Tendo em vista que são estimadas diversas árvores com diversos subconjuntos tanto de observações quanto de variáveis independentes, pode-se calcular a média de redução de impuridade (mean decrease impurity) que cada variável proporciona.\n",
    "\n",
    "Com isso, o modelo pode comparar a importância relativa de cada variável independente em conceder capacidade preditiva ao modelo, sendo assim uma ótima forma de se analisar a qualidade das variáveis testadas.\n",
    "\n",
    "Tudo isso é fornecido pelo atributo `feature_importances_` do modelo.\n",
    "\n",
    "**Obs.:** Quando o RandomForest realiza tarefas de regressão, é utilizada a variância dos resultados para calcular a importância relativa de uma variável."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.05751806, 0.45942431, 0.23445662, 0.248601  ])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variáveis</th>\n",
       "      <th>Importância</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sex</td>\n",
       "      <td>0.459424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fare</td>\n",
       "      <td>0.248601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Age</td>\n",
       "      <td>0.234457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pclass</td>\n",
       "      <td>0.057518</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Variáveis  Importância\n",
       "1       Sex     0.459424\n",
       "3      Fare     0.248601\n",
       "2       Age     0.234457\n",
       "0    Pclass     0.057518"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Colocando as variáveis em ordem crescente\n",
    "imp = pd.DataFrame({'Variáveis' : X_train.columns, 'Importância' : modelo.feature_importances_})\n",
    "imp.sort_values(by = ['Importância'], ascending = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "72bf47092338eed38b0780b83b91fd9a109f9b0b6603c4f71c3497fbd9ba9af9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
